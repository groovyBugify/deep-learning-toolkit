version: 0.2

env:
  variables:
    DOCKER_ACCOUNT: "dltk4splunk"
  #parameter-store:
  #  DOCKER_PASSWORD: /CodeBuild/DOCKER_PASSWORD

phases:
  install:
    commands:
      - BUILD_DIR=$CODEBUILD_SRC_DIR/build
      - IMAGES_DIR=$CODEBUILD_SRC_DIR/images
      # build spark-runtime images
      - SPARK_DIR=$IMAGES_DIR/spark
      - DLTK_SPARK_RUNTIME_DRIVER_IMAGE=$DOCKER_ACCOUNT/spark-runtime:driver-thin
      - DLTK_SPARK_RUNTIME_EXECUTOR_IMAGE=$DOCKER_ACCOUNT/spark-runtime:executor-thin
      - DLTK_SPARK_RUNTIME_DRIVER_PROXY_IMAGE=$DOCKER_ACCOUNT/spark-runtime:driver-proxy
      - DLTK_SPARK_RUNTIME_EDITOR_IMAGE=$DOCKER_ACCOUNT/spark-runtime:editor-thin
      - DLTK_SPARK_RUNTIME_INBOUND_RELAY_IMAGE=$DOCKER_ACCOUNT/spark-runtime:inbound-relay
      - DLTK_SPARK_RUNTIME_OUTBOUND_RELAY_IMAGE=$DOCKER_ACCOUNT/spark-runtime:outbound-relay
      - cd $SPARK_DIR
      - docker build --rm -f "./driver/thin.Dockerfile" -t $DLTK_SPARK_RUNTIME_DRIVER_IMAGE .
      - docker build --rm -f "./driver/thin.Dockerfile" -t $DLTK_SPARK_RUNTIME_EXECUTOR_IMAGE .
      - docker build --rm -f "./driver-proxy/Dockerfile" -t $DLTK_SPARK_RUNTIME_DRIVER_PROXY_IMAGE .
      - docker build --rm -f "./editor/thin.Dockerfile" -t $DLTK_SPARK_RUNTIME_EDITOR_IMAGE .
      - docker build --rm -f "./inbound-relay/Dockerfile" -t $DLTK_SPARK_RUNTIME_INBOUND_RELAY_IMAGE .
      - docker build --rm -f "./outbound-relay/Dockerfile" -t $DLTK_SPARK_RUNTIME_OUTBOUND_RELAY_IMAGE .
      # build base-runtime images
      - BASE_DIR=$IMAGES_DIR/base
      - cd $BASE_DIR
      - ./build.sh golden-image-gpu-4 phdrieger/ 4.0.0
      - DLTK_BASE_RUNTIME_IMAGE=$DOCKER_ACCOUNT/base-runtime:goldengpu
      - docker tag phdrieger/mltk-container-golden-image-gpu-4:4.0.0 $DLTK_BASE_RUNTIME_IMAGE
      # Install K3D
      - wget -q -O - https://raw.githubusercontent.com/rancher/k3d/main/install.sh | bash
      # Install HELM
      - curl https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | bash
      # Render Spark Operator charts
      - SPARK_OPERATOR=/spark_operator
      - mkdir $SPARK_OPERATOR
      - helm repo add incubator http://storage.googleapis.com/kubernetes-charts-incubator
      - helm template sparkoperator incubator/sparkoperator --set sparkJobNamespace=default --set serviceAccounts.sparkoperator.name=default --set serviceAccounts.spark.name=default --set operatorVersion=v1beta2-1.2.0-3.0.0 --set enableWebhook=true --output-dir=$SPARK_OPERATOR
      - rm $SPARK_OPERATOR/sparkoperator/templates/webhook-cleanup-job.yaml
      - rm $SPARK_OPERATOR/sparkoperator/templates/crd-cleanup-job.yaml
      #- ls $SPARK_OPERATOR/sparkoperator/templates/
      # Render HAProxy
      # https://github.com/helm/charts/tree/master/incubator/haproxy-ingress#configuration
      # https://github.com/jcmoraisjr/haproxy-ingress/blob/v0.6/README.md#rewrite-target
      - HAPROXY=/haproxy
      - mkdir $HAPROXY
      - helm repo add ingress-nginx https://kubernetes-charts-incubator.storage.googleapis.com
      - helm template haproxy incubator/haproxy-ingress --namespace default --set-string "controller.config.ssl-redirect=false" --output-dir=$HAPROXY
  build:
    commands:
      # Start Kubernetes Cluster (https://k3d.io/usage/commands/)
      - k3d cluster delete dltkbuild || true
      - k3d cluster create dltkbuild --wait --agents 0
      - k3d cluster list
      - K3D_ID=$(docker ps -aqf name=k3d-dltkbuild-serverlb)
      - KUBECONFIG_PATH=/kubeconfig
      - k3d kubeconfig get dltkbuild >> /tmp/$KUBECONFIG_PATH
      - printf '%s\n\n' "$(tail -n +2 /tmp/$KUBECONFIG_PATH)" >> $KUBECONFIG_PATH
      - sed -i 's/\(server:.*\):.\+/\1:6443/g' $KUBECONFIG_PATH
      # Build Helm
      - mkdir /helm
      - echo "FROM alpine/helm\n" > /helm/Dockerfile
      - echo "RUN mkdir /tmp/.kube" >> /helm/Dockerfile
      - echo "RUN echo $'\\" >> /helm/Dockerfile
      - cat $KUBECONFIG_PATH | awk -v ORS='\\n\\\n' 1 >> /helm/Dockerfile
      - echo "' > /tmp/.kube/config\n" >> /helm/Dockerfile
      - docker build -t helm /helm/.
      - docker run --network=container:$K3D_ID --rm --name helm -e "KUBECONFIG=/tmp/.kube/config" helm version
      # Build Kubectl
      - mkdir /kubectl
      - echo "FROM bitnami/kubectl\n" > /kubectl/Dockerfile
      - echo "RUN mkdir /tmp/.kube" >> /kubectl/Dockerfile
      - echo "RUN echo $'\\" >> /kubectl/Dockerfile
      - cat $KUBECONFIG_PATH | awk -v ORS='\\n\\\n' 1 >> /kubectl/Dockerfile
      - echo "' > /tmp/.kube/config\n" >> /kubectl/Dockerfile
      - docker build -t kubectl /kubectl/.
      # Wait for Kubernetes Cluster
      - docker run --network=container:$K3D_ID --rm -e "KUBECONFIG=/tmp/.kube/config" kubectl get nodes
      - echo "waiting for nodes ..."; docker run --network=container:$K3D_ID --rm -e "KUBECONFIG=/tmp/.kube/config" kubectl wait --for=condition=Ready node --all
      - docker run --network=container:$K3D_ID --rm -e "KUBECONFIG=/tmp/.kube/config" -i kubectl version
      - docker run --network=container:$K3D_ID --rm -e "KUBECONFIG=/tmp/.kube/config" -i kubectl create clusterrolebinding default-service-account-cluster-admin  --clusterrole=cluster-admin --serviceaccount=default:default
      # Start HAProxy
      - find $HAPROXY -name '*.yaml' -type f | xargs -I % sh -c 'cat %; printf "\n---\n"' | docker run --network=container:$K3D_ID --rm -e "KUBECONFIG=/tmp/.kube/config" -i kubectl apply -f -
      # Start Spark Operator
      - find $SPARK_OPERATOR -name '*.yaml' -type f | xargs -I % sh -c 'cat %; printf "\n---\n"' | docker run --network=container:$K3D_ID --rm -e "KUBECONFIG=/tmp/.kube/config" -i kubectl apply -f -
      # Start Ingress Controller
      - cat $BUILD_DIR/nginx.yaml | docker run --network=container:$K3D_ID --rm -e "KUBECONFIG=/tmp/.kube/config" -i kubectl apply -f -
      # Start HDFS
      - find $BUILD_DIR/hdfs -name '*.yaml' -type f | xargs -I % sh -c 'cat %; printf "\n---\n"' | docker run --network=container:$K3D_ID --rm -e "KUBECONFIG=/tmp/.kube/config" -i kubectl apply -f -
      # Start Splunk Operator
      - cat $BUILD_DIR/splunk_operator_for_kubernetes.yaml | docker run --network=container:$K3D_ID --rm -e "KUBECONFIG=/tmp/.kube/config" -i kubectl apply -f -
      # Start Splunk
      - cat $BUILD_DIR/splunk_environment.yaml | docker run --network=container:$K3D_ID --rm -e "KUBECONFIG=/tmp/.kube/config" -i kubectl apply -f -
      # Import base-runtime images
      - k3d image import $DLTK_BASE_RUNTIME_IMAGE -c dltkbuild
      # Import Spark images
      - k3d image import $DLTK_SPARK_RUNTIME_DRIVER_IMAGE $DLTK_SPARK_RUNTIME_EXECUTOR_IMAGE $DLTK_SPARK_RUNTIME_DRIVER_PROXY_IMAGE $DLTK_SPARK_RUNTIME_EDITOR_IMAGE $DLTK_SPARK_RUNTIME_OUTBOUND_RELAY_IMAGE $DLTK_SPARK_RUNTIME_INBOUND_RELAY_IMAGE -c dltkbuild
      # Wait for Spark Operator
      - echo "waiting for Spark operator ..."; docker run --network=container:$K3D_ID --rm -e "KUBECONFIG=/tmp/.kube/config" kubectl wait --for=condition=available --timeout=5m deployment/sparkoperator
      # Wait for HDFS
      - echo "waiting for hdfs datanode ..."; while [ "$(docker run --network=container:$K3D_ID --rm -e "KUBECONFIG=/tmp/.kube/config" kubectl get ds my-hdfs-datanode -o 'jsonpath={..status.numberReady}')" != "1" ]; do sleep 1; done
      - echo "waiting for hdfs namenode ..."; while [ "$(docker run --network=container:$K3D_ID --rm -e "KUBECONFIG=/tmp/.kube/config" kubectl get statefulset my-hdfs-namenode | grep 1/1 | wc -l)" != "1" ]; do sleep 1; done
      # Wait for Splunk Operator
      - echo "waiting for Splunk operator ..."; docker run --network=container:$K3D_ID --rm -e "KUBECONFIG=/tmp/.kube/config" kubectl wait --for=condition=available --timeout=1m deployment/splunk-operator
      # Wait for Splunk
      - echo "waiting for Splunk ..."; while [ "$(docker run --network=container:$K3D_ID --rm -e "KUBECONFIG=/tmp/.kube/config" kubectl get standalone dltk -o 'jsonpath={..status.phase}')" != "Ready" ]; do sleep 1; done
      - SPLUNK_ADMIN_PASSWORD="$(docker run --network=container:$K3D_ID --rm -e KUBECONFIG=/tmp/.kube/config kubectl get secret splunk-dltk-standalone-secrets -o jsonpath='{.data.password}' | base64 --decode)"
      # Package DLTK
      - pip install semantic_version
      - wget https://download.splunk.com/misc/packaging-toolkit/splunk-packaging-toolkit-1.0.1.tar.gz
      - pip install splunk-packaging-toolkit-1.0.1.tar.gz
      - DLTK_PACKAGE_DIR=/dltk_build
      - mkdir $DLTK_PACKAGE_DIR
      # https://dev.splunk.com/enterprise/docs/releaseapps/packagingtoolkit/pkgtoolkitref/packagingtoolkitcli#slim-package
      - mv $CODEBUILD_SRC_DIR/app $CODEBUILD_SRC_DIR/dltk
      - slim package -o $DLTK_PACKAGE_DIR $CODEBUILD_SRC_DIR/dltk
      - mv $CODEBUILD_SRC_DIR/dltk $CODEBUILD_SRC_DIR/app
      - DLTK_PACKAGE=$(find $DLTK_PACKAGE_DIR -maxdepth 1 -type f -name '*.tar.gz')
      - DLTK_PACKAGE_NAME=$(basename $DLTK_PACKAGE)
      # Install DLTK
      - TARGET_SPLUNK_POD_NAME="splunk-dltk-standalone-0"
      - cat $DLTK_PACKAGE | docker run --network=container:$K3D_ID -i --rm -e KUBECONFIG=/tmp/.kube/config kubectl exec -i $TARGET_SPLUNK_POD_NAME -- /bin/bash -c 'cat > /tmp/dltk.tgz'
      - docker run --network=container:$K3D_ID --rm -e KUBECONFIG=/tmp/.kube/config kubectl exec $TARGET_SPLUNK_POD_NAME -- /opt/splunk/bin/splunk install app -auth admin:${SPLUNK_ADMIN_PASSWORD} /tmp/dltk.tgz
      - docker run --network=container:$K3D_ID --rm -e KUBECONFIG=/tmp/.kube/config kubectl exec $TARGET_SPLUNK_POD_NAME -- sed -i '/^\[general\]/a python.version = python3' /opt/splunk/etc/system/local/server.conf
      - docker run --network=container:$K3D_ID --rm -e KUBECONFIG=/tmp/.kube/config kubectl exec $TARGET_SPLUNK_POD_NAME -- /opt/splunk/bin/splunk restart
      # Run tests
      - cd $CODEBUILD_SRC_DIR
      - tar -czvf /tmp/source.tar.gz *
      - docker run --network=container:$K3D_ID --rm -e KUBECONFIG=/tmp/.kube/config kubectl exec $TARGET_SPLUNK_POD_NAME -- mkdir /tmp/source
      - cat "/tmp/source.tar.gz" | docker run --network=container:$K3D_ID -i --rm -e KUBECONFIG=/tmp/.kube/config kubectl exec -i $TARGET_SPLUNK_POD_NAME -- /bin/bash -c 'cat > /tmp/source.tar.gz'
      - docker run --network=container:$K3D_ID --rm -e KUBECONFIG=/tmp/.kube/config kubectl exec $TARGET_SPLUNK_POD_NAME -- tar zxf /tmp/source.tar.gz -C /tmp/source
      - echo "$SPLUNK_ADMIN_PASSWORD" | docker run --network=container:$K3D_ID -i --rm -e KUBECONFIG=/tmp/.kube/config kubectl exec -i $TARGET_SPLUNK_POD_NAME -- /bin/bash -c 'cat > /tmp/SPLUNK_ADMIN_PASSWORD'
      - echo "$DLTK_BASE_RUNTIME_IMAGE" | docker run --network=container:$K3D_ID -i --rm -e KUBECONFIG=/tmp/.kube/config kubectl exec -i $TARGET_SPLUNK_POD_NAME -- /bin/bash -c 'cat > /tmp/DLTK_BASE_RUNTIME_IMAGE'
      - echo "$DLTK_SPARK_RUNTIME_DRIVER_IMAGE" | docker run --network=container:$K3D_ID -i --rm -e KUBECONFIG=/tmp/.kube/config kubectl exec -i $TARGET_SPLUNK_POD_NAME -- /bin/bash -c 'cat > /tmp/DLTK_SPARK_RUNTIME_DRIVER_IMAGE'
      - echo "$DLTK_SPARK_RUNTIME_EXECUTOR_IMAGE" | docker run --network=container:$K3D_ID -i --rm -e KUBECONFIG=/tmp/.kube/config kubectl exec -i $TARGET_SPLUNK_POD_NAME -- /bin/bash -c 'cat > /tmp/DLTK_SPARK_RUNTIME_EXECUTOR_IMAGE'
      - echo "$DLTK_SPARK_RUNTIME_DRIVER_PROXY_IMAGE" | docker run --network=container:$K3D_ID -i --rm -e KUBECONFIG=/tmp/.kube/config kubectl exec -i $TARGET_SPLUNK_POD_NAME -- /bin/bash -c 'cat > /tmp/DLTK_SPARK_RUNTIME_DRIVER_PROXY_IMAGE'
      - echo "$DLTK_SPARK_RUNTIME_EDITOR_IMAGE" | docker run --network=container:$K3D_ID -i --rm -e KUBECONFIG=/tmp/.kube/config kubectl exec -i $TARGET_SPLUNK_POD_NAME -- /bin/bash -c 'cat > /tmp/DLTK_SPARK_RUNTIME_EDITOR_IMAGE'
      - echo "$DLTK_SPARK_RUNTIME_INBOUND_RELAY_IMAGE" | docker run --network=container:$K3D_ID -i --rm -e KUBECONFIG=/tmp/.kube/config kubectl exec -i $TARGET_SPLUNK_POD_NAME -- /bin/bash -c 'cat > /tmp/DLTK_SPARK_RUNTIME_INBOUND_RELAY_IMAGE'
      - echo "$DLTK_SPARK_RUNTIME_OUTBOUND_RELAY_IMAGE" | docker run --network=container:$K3D_ID -i --rm -e KUBECONFIG=/tmp/.kube/config kubectl exec -i $TARGET_SPLUNK_POD_NAME -- /bin/bash -c 'cat > /tmp/DLTK_SPARK_RUNTIME_OUTBOUND_RELAY_IMAGE'
      - docker run --network=container:$K3D_ID --rm -e KUBECONFIG=/tmp/.kube/config kubectl exec $TARGET_SPLUNK_POD_NAME -- /bin/bash -c 'SPLUNK_PASSWORD="$(cat /tmp/SPLUNK_ADMIN_PASSWORD)" DLTK_BASE_RUNTIME_IMAGE="$(cat /tmp/DLTK_BASE_RUNTIME_IMAGE)" DLTK_SPARK_RUNTIME_DRIVER_IMAGE="$(cat /tmp/DLTK_SPARK_RUNTIME_DRIVER_IMAGE)" DLTK_SPARK_RUNTIME_EXECUTOR_IMAGE="$(cat /tmp/DLTK_SPARK_RUNTIME_EXECUTOR_IMAGE)" DLTK_SPARK_RUNTIME_DRIVER_PROXY_IMAGE="$(cat /tmp/DLTK_SPARK_RUNTIME_DRIVER_PROXY_IMAGE)" DLTK_SPARK_RUNTIME_EDITOR_IMAGE="$(cat /tmp/DLTK_SPARK_RUNTIME_EDITOR_IMAGE)" DLTK_SPARK_RUNTIME_INBOUND_RELAY_IMAGE="$(cat /tmp/DLTK_SPARK_RUNTIME_INBOUND_RELAY_IMAGE)" DLTK_SPARK_RUNTIME_OUTBOUND_RELAY_IMAGE="$(cat /tmp/DLTK_SPARK_RUNTIME_OUTBOUND_RELAY_IMAGE)" DLTK_INGRESS_URL="http://haproxy-haproxy-ingress-controller/" DLTK_INGRESS_CLASS="haproxy" DLTK_HDFS_HTTP_URL="http://my-hdfs-namenode:50070" DLTK_HDFS_URL="hdfs://my-hdfs-namenode" DLTK_APP_NAME="dltk" SKIP_TEST_UNLESS_=ListEnvironmentTestCase /opt/splunk/bin/splunk cmd python3 /tmp/source/test/test.py'
  post_build:
    commands:
      - k3d cluster delete dltkbuild
      - |
        if [ -n "$DOCKER_PASSWORD" ]; then
          set -e
          set -x
          echo $DOCKER_PASSWORD | docker login --username $DOCKER_ACCOUNT --password-stdin
          docker push $DLTK_SPARK_RUNTIME_DRIVER_IMAGE
          docker push $DLTK_SPARK_RUNTIME_EXECUTOR_IMAGE
          docker push $DLTK_SPARK_RUNTIME_DRIVER_PROXY_IMAGE
          docker push $DLTK_SPARK_RUNTIME_EDITOR_IMAGE
          docker push $DLTK_SPARK_RUNTIME_INBOUND_RELAY_IMAGE
          docker push $DLTK_SPARK_RUNTIME_OUTBOUND_RELAY_IMAGE
          docker push $DLTK_BASE_RUNTIME_IMAGE
        else
          echo 'Not pushing'
        fi