{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Toolkit for Splunk - Notebook for PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression in PyTorch\n",
    "This notebook contains an example for a simple logistic regression in PyTorch.<br>By default every time you save this notebook the cells are exported into a python module which is then used for executing your custom model invoked by Splunk MLTK Container App. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 0 - import libraries\n",
    "At stage 0 we define all imports necessary to run our subsequent code depending on various libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "name": "mltkc_import"
   },
   "outputs": [],
   "source": [
    "# this definition exposes all python module imports that should be available in all subsequent commands\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import torch\n",
    "# global constants\n",
    "MODEL_DIRECTORY = \"/srv/app/model/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing purposes\n",
    "print(\"numpy version: \" + np.__version__)\n",
    "print(\"scipy version: \" + sp.__version__)\n",
    "print(\"pandas version: \" + pd.__version__)\n",
    "print(\"PyTorch: \" + torch.__version__)\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"There are {torch.cuda.device_count()} CUDA devices available\")\n",
    "    for i in range(0,torch.cuda.device_count()):\n",
    "        print(f\"Device {i:0}: {torch.cuda.get_device_name(i)} \")\n",
    "else:\n",
    "    print(\"No GPU found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1 - get a data sample from Splunk\n",
    "In Splunk run a search to pipe a prepared sample dataset into this environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| inputlookup iris.csv <br>\n",
    "| fit MLTKContainer mode=stage algo=pytorch_nn epochs=10 species from petal_length petal_width sepal_length sepal_width into app:PyTorch_iris_model_nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you run this search your data set sample is available as a csv inside the container to develop your model. The name is taken from the into keyword (\"PyTorch_iris_model\" in the example above) or set to \"default\" if no into keyword is present. This step is intended to work with a subset of your data to create your custom model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "name": "mltkc_stage"
   },
   "outputs": [],
   "source": [
    "# this cell is not executed from MLTK and should only be used for staging data into the notebook environment\n",
    "def stage(name):\n",
    "    with open(\"data/\"+name+\".csv\", 'r') as f:\n",
    "        df = pd.read_csv(f)\n",
    "    with open(\"data/\"+name+\".json\", 'r') as f:\n",
    "        param = json.load(f)\n",
    "    return df, param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing purposes\n",
    "df, param = stage(\"PyTorch_iris_model_nn\")\n",
    "#print(param)\n",
    "print(df.describe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2 - create and initialize a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "name": "mltkc_init"
   },
   "outputs": [],
   "source": [
    "def init(df,param):\n",
    "    X = df[param['feature_variables']]\n",
    "    Y = df[param['target_variables']]\n",
    "    input_size = int(X.shape[1])\n",
    "    num_classes = len(np.unique(Y.to_numpy()))\n",
    "    learning_rate = 0.001\n",
    "    mapping = { key: value for value,key in enumerate(np.unique(Y.to_numpy().reshape(-1))) }\n",
    "    print(\"FIT build neural network model with input shape \" + str(X.shape))\n",
    "    print(\"FIT build model with target classes \" + str(num_classes))\n",
    "    model = {\n",
    "        \"input_size\": input_size,\n",
    "        \"num_classes\": num_classes,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"mapping\": mapping,\n",
    "        \"num_epochs\": 10000,\n",
    "        \"batch_size\": 100,\n",
    "        \"hidden_layers\" : 10,\n",
    "    }\n",
    "    device = None\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    model['device'] = device\n",
    "    \n",
    "    if 'options' in param:\n",
    "        if 'params' in param['options']:\n",
    "            if 'epochs' in param['options']['params']:\n",
    "                model['num_epochs'] = int(param['options']['params']['epochs'])\n",
    "            if 'batch_size' in param['options']['params']:\n",
    "                model['batch_size'] = int(param['options']['params']['batch_size'])\n",
    "            if 'hidden_layers' in param['options']['params']:\n",
    "                model['hidden_layers'] = int(param['options']['params']['hidden_layers'])\n",
    "\n",
    "    # Simple neural network model\n",
    "    model['model'] = torch.nn.Sequential(\n",
    "        torch.nn.Linear(model['input_size'], model['hidden_layers']),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(model['hidden_layers'], model['num_classes']),\n",
    "    ).to(model['device'])\n",
    "\n",
    "    # Define loss and optimizer\n",
    "    model['criterion'] = torch.nn.CrossEntropyLoss()  \n",
    "    model['optimizer'] = torch.optim.SGD(model['model'].parameters(), lr=learning_rate)      \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = init(df,param)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3 - fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "name": "mltkc_fit"
   },
   "outputs": [],
   "source": [
    "def fit(model,df,param):\n",
    "    returns = {}\n",
    "    X = df[param['feature_variables']].astype('float32').to_numpy()\n",
    "    Y = df[param['target_variables']].to_numpy().reshape(-1)\n",
    "    mapping = { key: value for value,key in enumerate(np.unique(Y)) }\n",
    "    Y = df[param['target_variables']].replace( {param['target_variables'][0]:mapping } ).to_numpy().reshape(-1)\n",
    "    if 'options' in param:\n",
    "        if 'params' in param['options']:\n",
    "            if 'epochs' in param['options']['params']:\n",
    "                model['num_epochs'] = int(param['options']['params']['epochs'])\n",
    "            if 'batch_size' in param['options']['params']:\n",
    "                model['batch_size'] = int(param['options']['params']['batch_size'])\n",
    "    print(model['num_epochs'])\n",
    "\n",
    "    inputs = torch.from_numpy(X).to(model['device'])\n",
    "    targets = torch.from_numpy(Y).to(model['device'])\n",
    "\n",
    "    for epoch in range(model['num_epochs']):\n",
    "        outputs = model['model'](inputs)\n",
    "        loss = model['criterion'](outputs, targets)\n",
    "        model['optimizer'].zero_grad()\n",
    "        loss.backward()\n",
    "        model['optimizer'].step()\n",
    "        if (epoch+1) % (model['num_epochs']/100) == 0:\n",
    "            print ('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, model['num_epochs'], loss.item()))                \n",
    "    # memorize parameters\n",
    "    returns['model_epochs'] = model['num_epochs']\n",
    "    returns['model_batch_size'] = model['batch_size']\n",
    "    returns['model_loss_acc'] = loss.item()\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = fit(model,df,param)\n",
    "print(returns['model_loss_acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 4 - apply the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "name": "mltkc_apply"
   },
   "outputs": [],
   "source": [
    "def apply(model,df,param):\n",
    "    X = df[param['feature_variables']].astype('float32').to_numpy()\n",
    "    classes = {v: k for k, v in model['mapping'].items()}\n",
    "    with torch.no_grad():\n",
    "        input = torch.from_numpy(X).to(model['device'])\n",
    "        output = model['model'](input)\n",
    "        y_hat = output.data\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        predicted = predicted.cpu()\n",
    "        prediction = [classes[key] for key in predicted.numpy()]\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = apply(model,df,param)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 5 - save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "name": "mltkc_save"
   },
   "outputs": [],
   "source": [
    "# save model to name in expected convention \"<algo_name>_<model_name>.h5\"\n",
    "def save(model,name):\n",
    "    torch.save(model, MODEL_DIRECTORY + name + \".pt\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 6 - load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "name": "mltkc_load"
   },
   "outputs": [],
   "source": [
    "# load model from name in expected convention \"<algo_name>_<model_name>.h5\"\n",
    "def load(name):\n",
    "    model = torch.load(MODEL_DIRECTORY + name + \".pt\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 7 - provide a summary of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "name": "mltkc_summary"
   },
   "outputs": [],
   "source": [
    "# return model summary\n",
    "def summary(model=None):\n",
    "    returns = {\"version\": {\"pytorch\": torch.__version__} }\n",
    "    if model is not None:\n",
    "        if 'model' in model:\n",
    "            returns[\"summary\"] = str(model)\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Stages\n",
    "All subsequent cells are not tagged and can be used for further freeform code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
